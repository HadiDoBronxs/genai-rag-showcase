import streamlit as st
import os
import shutil
from langchain_openai import ChatOpenAI
from langchain.chains.question_answering import load_qa_chain
from backend import StreamHandler, load_knowledge_base

def main():
    st.set_page_config(page_title="Chat with Hadi's Docs üìÇ", page_icon="ü§ñ")
    
    # --- 1. SESSION STATE INITIALISIEREN ---
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # --- 2. API KEY MANAGEMENT ---
    api_key = None
    try:
        if "OPENAI_API_KEY" in st.secrets:
            api_key = st.secrets["OPENAI_API_KEY"]
    except:
        pass

    if not api_key:
        with st.sidebar:
            st.title("‚öôÔ∏è Einstellungen")
            api_key = st.text_input("OpenAI API Key:", type="password")
            st.markdown("---")
            st.caption("Der Key wird nur f√ºr diese Sitzung genutzt.")
    
    if not api_key:
        st.info("üëã Willkommen! Bitte gib links deinen OpenAI API Key ein, um zu starten.")
        st.stop()

    st.header("ü§ñ Chat with Hadi's Portfolio")
    st.caption("Frage mich etwas zu Lebenslauf, Zeugnissen oder Zertifikaten!")

    # --- 3. WISSENSDATENBANK LADEN ---
    
    # Refresh Button
    with st.sidebar:
        if st.button("üîÑ Index aktualisieren"):
            # 1. Folder l√∂schen
            if os.path.exists("faiss_index"):
                shutil.rmtree("faiss_index")
            # 2. Cache l√∂schen
            load_knowledge_base.clear()
            # 3. Rerun
            st.rerun()

    with st.spinner("Lade Wissensdatenbank..."):
        knowledge_base = load_knowledge_base(api_key)
    
    if knowledge_base is None:
        st.warning("Keine Dokumente gefunden oder Fehler beim Erstellen der Datenbank.")
        st.stop()
    
    st.session_state.knowledge_base = knowledge_base

    # --- 4. CHAT INTERFACE ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Deine Frage an die Unterlagen..."):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            st_callback = StreamHandler(response_placeholder)
            
            # Relevante Textstellen finden
            docs = knowledge_base.similarity_search(prompt)
            
            llm = ChatOpenAI(model_name="gpt-3.5-turbo", openai_api_key=api_key, streaming=True)
            chain = load_qa_chain(llm, chain_type="stuff")
            
            system_instruction = "Du bist ein enthusiastischer HR-Assistent. Hebe Hadis St√§rken besonders hervor und antworte professionell aber √ºberzeugend. Antworte basierend auf dem Kontext. Wenn du etwas nicht wei√üt, sage es."
            
            response = chain.run(
                input_documents=docs, 
                question=f"{system_instruction}\nFrage: {prompt}",
                callbacks=[st_callback]
            )
            
            # Quellen anzeigen
            with st.expander("üìö Verwendete Quellen anzeigen"):
                seen_sources = set()
                for doc in docs:
                    source_id = f"{doc.metadata.get('source', 'Unbekannt')} (Seite {doc.metadata.get('page', '?')})"
                    if source_id not in seen_sources:
                        st.write(f"- {source_id}")
                        seen_sources.add(source_id)
            
            st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == '__main__':
    main()